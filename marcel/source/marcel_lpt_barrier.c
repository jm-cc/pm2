 
/* This file has been autogenerated from source/nptl_barrier.c.m4 */
/*
 * PM2: Parallel Multithreaded Machine
 * Copyright (C) 2001 "the PM2 team" (see AUTHORS file)
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or (at
 * your option) any later version.
 *
 * This program is distributed in the hope that it will be useful, but
 * WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * General Public License for more details.
 */
#include "marcel.h"

#include <errno.h>

#include "marcel_fastlock.h"

#ifdef MA__LIBPTHREAD
DEF_LIBPTHREAD(int, barrierattr_init,
	  (pthread_barrierattr_t * attr),
	  (attr))
DEF___LIBPTHREAD(int, barrierattr_init,
	  (pthread_barrierattr_t * attr),
	  (attr))
DEF_LIBPTHREAD(int, barrierattr_destroy,
	  (pthread_barrierattr_t * attr),
	  (attr))
DEF___LIBPTHREAD(int, barrierattr_destroy,
	  (pthread_barrierattr_t * attr),
	  (attr))
DEF_LIBPTHREAD(int, barrierattr_getpshared,
	  (pthread_barrierattr_t * __restrict attr, int* __restrict pshared),
	  (attr, pshared))
DEF_LIBPTHREAD(int, barrierattr_setpshared,
	  (pthread_barrierattr_t * attr, int pshared),
	  (attr, pshared))
versioned_symbol (libpthread, lpt_barrier_init,
                  pthread_barrier_init, GLIBC_2_2);
versioned_symbol (libpthread, lpt_barrier_destroy,
                  pthread_barrier_destroy, GLIBC_2_2);
versioned_symbol (libpthread, lpt_barrier_wait,
                  pthread_barrier_wait, GLIBC_2_2);
#endif

#ifdef MA__IFACE_LPT
int lpt_barrierattr_init(lpt_barrierattr_t *_attr) {
	struct lpt_barrierattr	* const attr = (struct lpt_barrierattr *)_attr;
        LOG_IN();  
	attr->pshared = LPT_PROCESS_PRIVATE;
        LOG_RETURN(0); 
}
int lpt_barrierattr_destroy (lpt_barrierattr_t *attr) {
        LOG_IN();       
        /* Nothing to do.  */
        LOG_RETURN(0);
}
int lpt_barrierattr_getpshared(__const lpt_barrierattr_t *_attr, int *pshared) {
	struct lpt_barrierattr	* const attr = (struct lpt_barrierattr *)_attr;
	LOG_IN();
	*pshared = attr->pshared;
	LOG_RETURN(0);
}
int lpt_barrierattr_setpshared (lpt_barrierattr_t *_attr, int pshared) {
	struct lpt_barrierattr	* const attr = (struct lpt_barrierattr *)_attr;
	LOG_IN();
	if (pshared != LPT_PROCESS_PRIVATE
	    && __builtin_expect(pshared != LPT_PROCESS_SHARED, 0)) {
		LOG_RETURN(EINVAL);
	}
	if (pshared == LPT_PROCESS_SHARED) {
		LOG_RETURN(ENOTSUP);
	}
	attr->pshared = pshared;
	LOG_RETURN(0);
}
int lpt_barrier_init(lpt_barrier_t *_b,
                        __const lpt_barrierattr_t *_attr,
                        unsigned int count) {
	struct lpt_barrier * const b	= (struct lpt_barrier *)_b;
	struct lpt_barrierattr	* const attr = (struct lpt_barrierattr *)_attr;
	LOG_IN();
	if (__builtin_expect(count == 0, 0)) {
		LOG_RETURN(EINVAL);
	}
	if (attr != NULL) {
		if (attr->pshared != LPT_PROCESS_PRIVATE
		    && __builtin_expect(attr->pshared != LPT_PROCESS_SHARED,
			0)) {
			LOG_RETURN(EINVAL);
		}
		if (attr->pshared == LPT_PROCESS_SHARED) {
			LOG_RETURN(ENOTSUP);
		}
	}
	b->lock = (struct _lpt_fastlock) MA_LPT_FASTLOCK_UNLOCKED;
	b->init_count = count;
	ma_atomic_init(&b->leftB, count);
	ma_atomic_init(&b->leftE, 0);
	LOG_RETURN(0);
}
int lpt_barrier_destroy (lpt_barrier_t *_b) {
	struct lpt_barrier * const b	= (struct lpt_barrier *)_b;
	int ret = 0;
	LOG_IN();
	lpt_lock_acquire(&b->lock.__spinlock);
	while (ma_atomic_read(&b->leftE)) {
		blockcell c;
		__lpt_register_spinlocked(&b->lock, marcel_self(),
				&c);
		INTERRUPTIBLE_SLEEP_ON_CONDITION_RELEASING(c.blocked,
				lpt_lock_release(&b->lock.__spinlock),
				lpt_lock_acquire(&b->lock.__spinlock));
	}
	if (__builtin_expect(ma_atomic_read(&b->leftB) != b->init_count, 0)) {
		ret = EBUSY;
	}
	lpt_lock_release(&b->lock.__spinlock);
	LOG_RETURN(ret);
}
int lpt_barrier_wait(lpt_barrier_t *b) {
	int ret = 0;
	LOG_IN();
	lpt_barrier_wait_begin(b);
	if (!lpt_barrier_wait_end(b))
		ret = LPT_BARRIER_SERIAL_THREAD;
	LOG_RETURN(ret);
}
int lpt_barrier_wait_begin(lpt_barrier_t *_b) {
	struct lpt_barrier * const b	= (struct lpt_barrier *)_b;
	LOG_IN();
	lpt_lock_acquire(&b->lock.__spinlock);
	while (ma_atomic_read(&b->leftE)) {
		blockcell c;
		__lpt_register_spinlocked(&b->lock, marcel_self(),
				&c);
		INTERRUPTIBLE_SLEEP_ON_CONDITION_RELEASING(c.blocked,
				lpt_lock_release(&b->lock.__spinlock),
				lpt_lock_acquire(&b->lock.__spinlock));
	}
	int ret = ma_atomic_dec_return(&b->leftB);
	if (!ret) {
		while (__lpt_unlock_spinlocked(&b->lock));
		ma_atomic_set(&b->leftB, b->init_count);
		ma_atomic_set(&b->leftE, b->init_count);	
	}
	lpt_lock_release(&b->lock.__spinlock);
	LOG_RETURN(ret);
}
int lpt_barrier_wait_end(lpt_barrier_t *_b) {
	struct lpt_barrier * const b	= (struct lpt_barrier *)_b;
	LOG_IN();
	lpt_lock_acquire(&b->lock.__spinlock);
	while (!ma_atomic_read(&b->leftE)) {
		blockcell c;
		__lpt_register_spinlocked(&b->lock, marcel_self(),
				&c);
		INTERRUPTIBLE_SLEEP_ON_CONDITION_RELEASING(c.blocked,
				lpt_lock_release(&b->lock.__spinlock),
				lpt_lock_acquire(&b->lock.__spinlock));
	}
	int ret = ma_atomic_dec_return(&b->leftE);
	if (!ret)
		while (__lpt_unlock_spinlocked(&b->lock));
	lpt_lock_release(&b->lock.__spinlock);
	LOG_RETURN(ret);
}
#endif

