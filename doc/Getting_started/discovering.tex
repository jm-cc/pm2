\chapter{Discovering PM2}

\stamp $Id: discovering.tex,v 1.4 2001/04/18 15:13:12 bouge Exp $

This chapter aims at illustrating the basic features of PM2 through
some very simple programs. Next chapters present more advanced
features that may be needed when developing \emph{real} parallel
applications.

\section{Compiling your own PM2 program}

\figurelisting {Makefile1} {A minimal GNU Makefile for PM2
  programs} {prog:Makefile1}

You may compile you own PM2 program just as a usual C~program. The
only point is to include the necessary definitions and libraries.  As
the command line is rather complex, PM2 provides a simple utility to
generate it on-line: \|pm2-config --cc| generates the name of the
adequate C~compiler (most probably, \|gcc|), \|pm2-config --cflags|
generates the necessary \|CFLAGS|, and \|pm2-config --libs| generates
the list of libraries to be searched on linking. Thus, the standard
command line to compile a PM2 program \|hello.c| looks like:
\begin{shell}
# Assuming you use csh...
setenv CC       "`pm2-config --cc`"
setenv CFLAGS   "`pm2-config --cflags`"
setenv LIBS     "`pm2-config --libs`" 
$CC $CFLAGS hello.c $LIBS -o hello
\end{shell}
Observe that the source file \|hello.c| should be mentioned
\emph{before} the PM2 libraries, as the external symbols are searched by
\|gcc| in the libraries from left to right.

Well... Such a command line is rather tedious to enter! You will find
on Figure~\ref{prog:Makefile1} a \|Makefile| which does all the work
for you. Executing \|make hello| will compile source file \|hello.c|
with all the necessary parameters.

Observe that using dynamic calls to the \|pm2config| utility guarantees
that you are compiling with the suitable options with respect to the
current value of the flavor, as specified by the \|PM2_FLAVOR|
shell variable.

\section{Hello World!}

Let us start our PM2 tour by writing the traditional ``\emph{Hello
  World!}'' program. Then, we will extend it step by step to cover the
main functionalities provided by the PM2 programming interface.

\subsection{The minimal PM2 program}

\figurelisting {hello.c} {Minimal PM2 program} {prog:hello}

Figure~\ref{prog:hello} shows an
example of a minimal PM2 code. Compile it and run it:
\begin{shell}
ravel% make hello
[...]   # Normally, no warning whatsoever!

ravel% pm2conf ravel debussy faure
The current PM2 configuration contains 3 host(s) :
0 : ravel
1 : debussy
2 : faure

ravel% pm2load hello
[Threads : 2 created, 0 imported (0 cached)]
Hello World!
\end{shell}
Though it looks simple, it is a full-fledged SPMD parallel program
that spawns on several processing nodes during execution! Let's
examine it step by step.

\subsubsection{Header files}

A PM2 program must always include the PM2-specific \|pm2.h| header
file, along with other standard header files.  Note that this is the
\emph{only} PM2 header file that has to be included by user
applications.

\subsubsection{The \|pm2_main| function}

The main function of the PM2 program is named \|pm2_main|, in contrast
to traditional C~programs that use the well-known \|main|
function name. In fact, the \emph{real} \|main| function of the
program is provided by the PM2 libraries. It has to set up the
execution environment before calling the user \|pm2_main| function.
This allows PM2 to greatly enhance the performance of various thread
management functions.  The arguments remain the regular
\|argc|/\|argv| pair, with their usual meaning.

Although most programs (or rather, programmers!) can accommodate such a
violation of the usual \emph{C~convention}, there exists some
applications that require to use the regular \|main| function name. In
particular, it may be the case with applications linked with non-C
code (\emph{e.g.}, Fortran code).  In this case, please refer to
Section~\ref{sec:tradimain} for details.

\subsubsection{PM2 initialization}

A PM2 program has to call \|pm2_init| to effectively initialize the
PM2 runtime system. Moreover, this step involves a global
synchronization phase (actually, a global synchronization barrier)
among all the PM2 nodes so that each process is assigned a unique
\emph{rank number} on returning from \|pm2_init|. In consequence, it
makes no sense to call functions concerned with the global execution
environment (such as node numbers, etc.)  \emph{before} this point.
Please, refer to Section~\ref{sec:rank} for details.

Most importantly, the \|pm2_init| function spawns a number of internal
\emph{thread daemons} that are in charge of listening the network and
answering to external requests such as RPCs, incoming thread
migrations, etc. A node should be ready to handle all possible
incoming requests from any other node at this point. As a consequence,
it is not safe to do any initialization \emph{after} this point, as
the user has no control about the interleaving of requests and the
relative speed of the nodes. Even though the initialization call is
placed just after \|pm2_init|, an arbitrary delay may occur between
the two successive instructions! It follows that if some
initialization code needs to be performed before any thread is
started, then this code \emph{must} be called \emph{before}
\|pm2_init|.

Note also that the Unix standard input/output streams may not be
correctly initialized before the call to \|pm2_init|. Thus, the
behavior of programs using I/O operations before \|pm2_init| is not
defined.

Going back to our example program, note the call to the \|tprintf|
routine of PM2. This is a simple wrapper of the regular \|printf|
routine of the C~library, which is protected against multithreading
(technically, it is made \emph{reentrant} by disabling scheduling).
As mentioned previously, all nodes perform this call and actually
produce the ``\emph{Hello World!}'' string on their output stream.
Yet, only the output of node~0 is observed here.
Section~\ref{sec:output} describes where these outputs actually go
during execution.

\subsubsection{Who's who?}
\label{sec:rank}

Each processing node (that is, Unix process) taking part to a given
execution receives its own unique \emph{rank} number. This is an
\|unsigned int| between 0 and $(\mbox{\|pm2_config_size ()|} - 1)$. A
node can learn its own rank by calling the \|pm2_self| routine.

The processing node with rank~0 has a particular status because it is
the only one which whose input/output streams are linked to the
terminal the application was launched from. We later refer to this
process as the \emph{main node} of an application. As a consequence,
only the main node of an application can access its standard input
stream (\emph{e.g.}, using \|scanf|, \|gets|, etc.)

As an example of use of \|pm2_self|, the program features a test on
the rank of the current process: if the current process is the main
process, then the \|pm2_halt| routine is called.

\subsubsection{How to terminate?}

The termination of a PM2 program is a delicate task since PM2 performs
no automatic termination detection. Thus, the termination decision
must be made at the application level. The termination phase is
split in two steps.

\emph{Exactly one} node must perform an explicit call to
\|pm2_halt|. In our example, the main process was chosen to execute
this function.  Actually, any process could have been selected. For
instance, we could replace 
\begin{program}
if(pm2_self () == 0)
\end{program}
by any other kind of test selecting exactly one node, for instance:
\begin{program}
if(pm2_self () == pm2_config_size () - 1)
\end{program}

At least conceptually, the \|pm2_halt| routine performs a broadcast
that requires all nodes to stop answering to requests from the outside
world. In fact, this step cuts the links between nodes: it stops the
internal daemon threads that are in charge of polling the network.
Note that after a node receives this order, it still continues its
normal execution in a \emph{standalone} mode: \emph{halting} is no
\emph{killing}!

To exit from a PM2 session, each node must call the \|pm2_exit|
routine.  This call blocks the calling thread until all other threads
(belonging to the same node) terminate. In our example, no other
application thread but the main one is running. Thus, \|pm2_exit|
completes as soon as the internal daemon threads are stopped. Had we
removed the call to \|pm2_halt|, then all nodes would remain hanging,
waiting for ever for external requests!

As the call to \|pm2_exit| is potentially blocking, the thread in
charge of calling \|pm2_halt| should do it first. However, observe
that it may well be the case that at a node, some thread is in charge
of calling \|pm2_halt| and another one \|pm2_exit|, so that the order
may in fact be irrelevant.

From the user point of view, the PM2 program terminates as soon as the
shell prompts for the next command from the terminal. This corresponds
to the end of the main node. However, note that some nodes may
actually remains running after the main node has completed.  In our example,
the main node can even terminate before any other node has started
executing \|tprintf|! Fortunately, this is not a problem here, since
\|tprintf| does not involve any communication with other nodes. We will
further discuss this termination problem in Section~\ref{sec:output}.

\begin{note}
  LB: Is there a specific ordering to call halt and exit? In this
  section, I suggest that it is not relevant!
\end{note}


\subsection{Where does the output go?}
\label{sec:output}

This simple \|hello| program only printed the message generated by the
master node node. Indeed, the standard output of the other nodes is
redirected to local log files located into the \|/tmp| directory.  The
logs are easily accessible using the command \|pm2logs| which is in
charge of retrieving and displaying logs from each slave node of the
session configuration. Observe that such requests are quite slow, as
they use \|rsh| connections:
\begin{shell}
ravel% pm2logs
*** Process 1 on debussy:
[Threads : 2 created, 0 imported (0 cached)]
Hello World!
*** Process 2 on faure:
[Threads : 2 created, 0 imported (0 cached)]
Hello World!
\end{shell}

\figurelisting{hello1.c} {Output redirection,
  Example~1} {prog:hello1}

Observe that there is no reason why all the nodes should make the
\emph{same} output requests. Consider for instance the variant of the
\|hello| program on Figure~\ref{prog:hello1}. Only node~1 outputs a
message.  Also, just to show you that any node can force termination,
node~2 is this time in charge of it!
\begin{shell}
ravel% make hello1
[...]

ravel% pm2load hello1
[Threads : 2 created, 0 imported (0 cached)]

ravel% pm2logs
*** Host debussy, process 1:
[Threads : 2 created, 0 imported (0 cached)]
Hello World from node 1!
*** Host faure, process 2:
[Threads : 2 created, 0 imported (0 cached)]
\end{shell}

\subsubsection{Redirecting output to the terminal}

For user convenience, it is possible to redirect output directly
to the output of the master node using the \|pm2_printf| function. As
\|tprintf|, it is protected against multithreading. Moreover, it sends
its output as a regular message to node~0, where it is printed out.
However, the user must be aware that this facility should be used with
caution, as it uses the common communication subsystem. 

\figurelisting{hello2.c} {Output redirection,
  Example~2} {prog:hello2}

Consider program \|hello2| on Figure~\ref{prog:hello2}. The output is
immediately printed on the terminal attached to the master node. The
\|[t1]| label is inserted to identify the outputting node. By
convention, outputs from node~0 have no label, so as to mimic the
behavior of the original \|printf| function.
\begin{shell}
ravel% pm2load hello2
[t1] Hello World !
[Threads : 2 created, 0 imported (0 cached)]
\end{shell}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Remote Procedure Calls}

The goal of this section is to let you issue a \emph{Remote Procedure
  Call} in PM2. We start with a basic scheme, and we refine it step by
  step so as to demonstrate the versatility of PM2.

\subsection{Invoking a remote service}

\figurelisting {rpc.c} {Defining a service in PM2} {prog:rpc}

A \emph{service} is a function located on a \emph{server} node, which
can be invoked by some \emph{client} node. Observe that the client
node may be the same as the server node. It may also be run on the
same processor, or on a sibling processor on the same SMP board, or on
some remote one. All this is fully transparent for the user of PM2.
Nodes are specified through their numbers, as allocated by the
\|pm2conf| command. In this part, we consider our usual 3-node
configuration:
\begin{shell}
ravel% pm2conf ravel debussy faure
The current PM2 configuration contains 3 host(s) :
0 : ravel
1 : debussy
2 : faure
\end{shell}

In Program~\ref{prog:rpc}, a basic service is defined. Its behavior is
to print \|Hello, World!| on the standard output of the node which is
executing it. At the level of PM2, a \emph{service} is just an \|int|
associated to some function using the \|pm2_rawrpc_register| routine.
Observe that the service function takes no argument.

Of course, all the available servers have to be registered
\emph{before} they may be invoked. The association between the service
identifier and the service function has thus to be set up
\emph{before} calling the \|pm2_init| routine. Doing otherwise will
result in unspecified behavior, probably depending on the relative
speed of the nodes. The user is therefore \emph{strongly advised} to
pay very careful attention to this requirement.

Returning to the program, processing node~0 invokes the remote service
\|service_id| on processing node~1. The service invocation is
initiated using the \|pm2_rawrpc_begin| routine.  The first argument
of the routine is the unique number of the server node.  The second
argument is the service identifier. It has to be a valid number on the
\emph{server node}.  The third argument is used for specifying
additional \emph{attributes} to be discussed later. In this basic
case, no additional data is to be provided together with the service
invocation, and \|NULL| is a sensible default. The \|pm2_rawrpc_end|
routine finalizes the service invocation. Returning from this routine
guarantees that the service invocation has been completed from the
client's point of view.

In this example, the service is synchronous: the \|pm2_rawrpc_end|
returns in the client node only \emph{after} the service function has
returned on the remote server node. Thus, the client node can safely
call \|pm2_halt| to force the termination of the distributed program.

It is now time to run the program:
\begin{shell}
ravel% pm2load rpc
[Threads : 2 created, 0 imported (0 cached)]

ravel% pm2logs
*** Process 1 on debussy:
[Threads : 2 created, 0 imported (0 cached)]
Hello, World!
*** Process 2 on faure:
[Threads : 2 created, 0 imported (0 cached)]
\end{shell}
Observe that an image of the program has been started \emph{both} on
hosts \|debussy| and \|faure|. In fact, the service function has been
registered on all 3 nodes, including root node~0.  Yet, only 
node~1 has been used as a server for the request of node~0.

In this example, the two processing nodes of PM2 have been launched on
two distinct machines for the sake of clarity.  However, the machine
running the server node may well be the same as the one running the
client node:
\begin{shell}
ravel% pm2conf debussy debussy debussy
The current PM2 configuration contains 3 host(s) :
0 : debussy
1 : debussy
2 : debussy

ravel% pm2load rpc
[Threads : 2 created, 0 imported (0 cached)]

ravel% pm2logs
*** Host debussy, process 1:
[Threads : 2 created, 0 imported (0 cached)]
Hello, World!
*** Host debussy, process 2:
[Threads : 2 created, 0 imported (0 cached)]
\end{shell}

The careful reader will have noticed that the definition of the
service function includes a call to the \|pm2_rawrpc_waitdata|
routine. This is necessary to instruct the service function that no
additional data is to be expected, so that it can proceed safely.
Actually, the service function has no way of discovering that the RPC
has been invoked without any additional data, and it is up to the user
to build the program client and server parts of the program in a
consistent way. More on this in the next section!

\subsection{Passing parameters}

\figurelisting {rpc-params.c} {Service with a string
  parameter} {prog:rpc-params}

Let us now the case of a service function invoked with additional
parameters. In Program~\ref{prog:rpc-params}, node~0 invokes a service
on node~1 with a string as a parameter. The service consists namely in
printing the string on the standard output.
  
Which string? Well, the original motivation of PM2 was to provide a
runtime environment for high-performance distributed programs with a
highly irregular behavior: branch-and-bound search, computation on
sparse matrices, etc. In one word: In Search of Lost Time, \emph{\`A
  la recherche du temps perdu!} You may remember that a
\emph{Madeleine}, a typically French (delicious) cookie, played a
central role in the life of \emph{Marcel} Proust...
  
On the client side, the parameters of the service are \emph{packed}
together between the \|pm2_rawrpc_begin| and the \|pm2_rawrpc_end|
calls, using the \|pm2_pack_*| routine family. You can pack integers,
byte arrays, etc. (even pointers!) very much as in PVM or PMI.  On the
server side, they are \emph{unpacked} within the service function.
Again, the service function has no way of guessing what kind of
parameters have been packed by the client, nor how many of them have
been packed. In short, PM2 message are \emph{not self-described}.
This choice is motivated by performance considerations: including the
description of the objects together with the objects into the messages
yields a significant overhead for small messages. In this respect, PM2
follows the choice of many other communication interfaces. The
counterpart is that the user is responsible for the consistency of the
series of packing and unpacking actions. No verification is made at
the level of PM2, and unspecified behavior will result of any
inconsistency in types and numbers. The user specifies the end of
reception on the server side by a call to the \|pm2_rawrpc_waitdata|
routine.

Let us now run the program.
\begin{shell}
ravel% pm2load rpc-params
[Threads : 2 created, 0 imported (0 cached)]

ravel% pm2logs
*** Process 1 on debussy:
[Threads : 2 created, 0 imported (0 cached)]
The sentence is: A la recherche du temps perdu.
*** Process 2 on faure:
[Threads : 2 created, 0 imported (0 cached)]
\end{shell}

\begin{warning}
  Program~\ref{prog:rpc-params} and similar programs may not work
  properly when used with communication interfaces which require some
  specific alignment for communication buffers: for instance,
  BIP/Myrinet and SISCI/SCI. In this case, variable \|s| should
  be aligned to a proper boundary. This can be done for instance as
  follows using the specific attributes of \|gcc|:
\begin{program}
#define __ALIGNED__ __attribute__ ((aligned (sizeof(int))))
char s[16] __ALIGNED__;
\end{program}
\end{warning}

\subsection{The packing/unpacking API}

The packing model of PM2 has been carefully designed so as to enable
high-performance communication on modern Gigabit network interfaces
such as BIP/Myrinet, SISCI/SCI, VIA, etc. In this context, it is of
uttermost significance to save copies: actually, the time for copying
a buffer within a node is of the same order of magnitude as the time
for sending it on the network to some remote node!  The key for
performance is therefore to allow for \emph{zero-copy}
communication: the message has to be directly taken from its initial
location in user-space, and directly placed into its final destination
in user space, without any additional copy. As the size of the
arguments for a RPC call are usually unknown in advance, the
communication interface has to include this feature into its design.
The approach of PM2, or more accurately of the underlying
communication library called Madeleine, is to control the packing and
unpacking operations with additional \emph{flags}.

A message consists of several pieces of data, located anywhere in
user space. It is constructed (resp. de-constructed) incrementally
using \emph{packing} (resp. \emph{unpacking}) routines, possibly at
multiple software levels without losing efficiency. The following
example illustrates this need. Let us consider a remote procedure call
which takes an array of unpredictable size as a parameter. When the
request reaches the destination node, the header is examined both by
the multithreaded runtime (to allocate the appropriate thread stack
and then to spawn the server thread) and by the user application (to
allocate the memory where the array should be stored).

The critical point of a sending operation is obviously the series of
\emph{packing} calls. Such packing operations simply \emph{virtually}
append the piece of data to a message under construction. In addition
to the address of data and its size, the packing primitive features a
\emph{flag} parameter which specifies the semantics of the operation.
Available sending flags are defined as follows:
\begin{description}
    
\item[\|SEND_SAFER|] This flag indicates that PM2 should pack the data
  in a way that further modifications to the corresponding memory area
  should not corrupt the message. This is particularly mandatory if
  the data location is reused before the message is actually sent.
  
\item[\|SEND_LATER|] This flag indicates that PM2 should not consider
  accessing the value of the corresponding data until the
  \|pm2_end_packing| primitive is called. This means that any
  modification of these data between their packing and their sending
  shall actually update the message contents.
    
\item[\|SEND_CHEAPER|] This is the default flag. It allows PM2 to do
  its best to handle the data as efficiently as possible. The
  counterpart is that no assumption should be made about the way PM2
  will access the data. Thus, the corresponding data should be left
  unchanged until the send operation has completed. Note that most
  data transmissions involved in parallel applications can accommodate
  the \|send_CHEAPER| semantics.

\end{description}
The following flags control the reception of user data packets:
\begin{description}
    
\item[\|RECV_EXPRESS|] This flag forces PM2 to guarantee that the
  corresponding data are immediately available after the the
  \emph{unpacking} operation. Typically, this flag is mandatory the
  data is needed to determine the next forthcoming \emph{unpacking}
  calls.  On some network protocols, this functionality may be
  available for free. On some others, it could penalize latency and
  bandwidth. The user should therefore extract data this way only when
  necessary.
    
\item[\|RECV_CHEAPER|] This flag allows PM2 to defer the extraction of
  the corresponding data until the execution of the
  \|pm2_rawrpc_waitdata| routine.  Thus, no assumption can be made
  about the exact moment at which the data will be extracted.
  Depending on the underlying network protocol, PM2 will do its best
  to minimize the overall message transmission time. If combined with
  \|send_CHEAPER|, this flag always guarantees that the corresponding
  data is transmitted as efficiently as possible.

\end{description}
Observe that the emission and reception flags should be \emph{both}
specified  by the matching packing/unpacking calls, and these
specifications should be identical. Again, unspecified behavior would
result from mismatching flags.

In Program~\ref{prog:rpc-params}, everything is sent \|CHEAPER|, so as
to save time. The user has been careful enough not to corrupt
variables \|len| and \|s| before calling \|pm2_rawrpc_end|. On the
reception side, variable \|len| \emph{must} be received \|EXPRESS|, as
its value is needed to allocate the buffer for the unpacking of
variable \|s|.  Then, variable \|s| can be received \|CHEAPER|. If the
underlying operating system and network interface permit, then this
(possibly large) message will thus be directly installed into the
reception buffer without any extra copy, providing the user with
optimal performance.

\subsection{Threaded services}

Services handlers are executed sequentially. As long as a service
function has not returned on the server, the service is not available
for another client. This may result into deadlocks if the service
includes some potentially blocking actions, such as invoking other
services, either explicitly or implicitly.

\figurelisting {rpc-threads.c} {Spawning a fresh thread to serve a
  remote request} {prog:rpc-threads}

Such problems can be addressed by executing services into a fresh
threads instead of the original service handler. This technique is
demonstrated on Program~\ref{prog:rpc-threads}. Service function
\|service| spawns a fresh thread each time it is invoked
through a RPC request. Then, it immediately returns. The child thread
is in charge of extracting the message from the network through a series
of \|unpack| calls in the usual way. 

Observe that PM2 do not care about \emph{who} extracts a message at a
node. Any thread can do it, as soon as it has been created with a
special creation routine \|pm2_service_thread_create|, instead of the
regular \|pm2_thread_create| one. The only requirement enforced within
the runtime system is that the same thread unpacks the series of data
pieces and calls the \|pm2_rawrpc_waitdata| routine. Having two or
more threads extracting data from the network concurrently would
actually not make sense: it may raise a run-time error.

\begin{note}
  Luc to Olivier + Raymond: Is it right? A sentence should probably be
  inserted here to warn that this behavior may be revised in the
  future versions.
\end{note}

This feature enables the newly spawn thread to do the work for the
sake of the original service handler. Yet, this raises a new
problem. Actually, the service handler immediately returns after
spawning the thread, and then looses any control on its
progression. Thus, the \|pm2_rawrpc_end| routine on the client side
may return \emph{before} the service thread has even started any
unpacking whatsoever! 

This may result in an incorrect behavior, as demonstrated by the
following scenario. Consider that the client is very fast. After
exiting the \|pm2_rawrpc_end| routine, it calls the \|pm2_halt|
routine. This triggers broadcasting a termination request to all the
nodes. Assume now that the messages used on this broadcast do not
travel on the same \emph{channel} as the regular messages, so that
they can take over and arrive \emph{before} the service thread
initiates the unpacking. Then, all the reception facilities of the
server node are closed down. When the daemon service thread finally
calls the \|pm2_unpack_*| routine, nobody remains living here to
physically extract the data from the network, and a run-time error
results!

Well, you may argue that this scenario is just like SF and little
green men attacking the White House... The writer's personal
experience is that the worse case is quite common in this matter, in
opposite~(?) to other domain of life. Just don't try!

How can one circumvent the problem? A generic technique called
\emph{completion} will be introduced later. In the specific example
displayed on Figure~\ref{prog:rpc-threads}, a simple way-out is to let
the service thread issue the call to the \|pm2_halt| routine, as it is
guaranteed that this thread issues the inter-thread last interaction.

Let us now run the program. Observe that 3 threads have been
created on node~1, instead of the regular~2.
\begin{shell}
ravel% pm2load rpc-threads
[Threads : 2 created, 0 imported (0 cached)]

ravel% pm2logs
*** Process 1 on debussy:
[Threads : 3 created, 0 imported (0 cached)]
Hello world!
*** Process 2 on faure:
[Threads : 2 created, 0 imported (0 cached)]
\end{shell}

\figurelistingdouble {rpc-threads1.c} {Spawning threads to serve
  requests, an extended example} {prog:rpc-threads1}

To have a bit more fun on closing this part, let us design a slightly
more complex program, as the one on Figure~\ref{prog:rpc-threads1}.
Node~0 issues a RPC request to node~1. On node~1, servicing this
request consists in spawning a fresh thread and re-issuing the request
to node~2 after having signed it with its name.  Similarly for node~2
with respect to node~0. Finally, node~0 serves the request by printing
the string to the standard output and triggers termination.
\begin{shell}
ravel% pm2load rpc-threads1
[Threads : 3 created, 0 imported (0 cached)]
Sending string: Init
Received back string: Init 1 2

ravel% pm2logs
*** Process 1 on debussy:
[Threads : 3 created, 0 imported (0 cached)]
Passing on string: Init 1
*** Process 2 on faure:
[Threads : 3 created, 0 imported (0 cached)]
Passing on string: Init 1 2
\end{shell}

It is a good point to clarify the notion of a \emph{node} used
throughout this presentation. Actually, the nodes we are considering
here are \emph{virtual}: they only refer to Unix processes located on
physical nodes. It looks like common sense practice to exactly use one
virtual node per physical node, so that the two notions just match
together. But nothing in PM2 requires such an identification. PM2
virtual nodes may be located at any physical nodes. The precise
association is made by the \|pm2conf| command. For instance, saying
\begin{shell}
ravel% pm2conf ravel debussy faure ravel debussy faure
\end{shell}
is just as right as anything else. Two processes are launched on each
of the three machines. From the point of view of PM2 programs, this
makes no difference.
\begin{shell}
ravel% pm2conf ravel debussy faure ravel debussy faure 
The current PM2 configuration contains 6 host(s) :
0 : ravel
1 : debussy
2 : faure
3 : ravel
4 : debussy
5 : faure

ravel% pm2load rpc-threads1
[Threads : 3 created, 0 imported (0 cached)]
Sending string: Init
Received back string: Init 1 2 3 4 5
\end{shell}
You may even start all processes on the same machine!
\begin{shell}
ravel% pm2conf ravel ravel ravel ravel ravel ravel
The current PM2 configuration contains 6 host(s) :
0 : ravel
1 : ravel
2 : ravel
3 : ravel
4 : ravel
5 : ravel

ravel% pm2load rpc-threads1
[Threads : 3 created, 0 imported (0 cached)]
Sending string: Init
Received back string: Init 1 2 3 4 5
\end{shell}
Also, there is no reason why this machine should be the one which you
are logged in. Any machine can make it as well!
\begin{shell}
ravel% pm2conf debussy debussy debussy debussy debussy debussy
The current PM2 configuration contains 6 host(s) :
0 : debussy
1 : debussy
2 : debussy
3 : debussy
4 : debussy
5 : debussy

ravel% pm2load rpc-threads1
[Threads : 3 created, 0 imported (0 cached)]
Sending string: Init
Received back string: Init 1 2 3 4 5
\end{shell}
