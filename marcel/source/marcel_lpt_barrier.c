
/* This file has been autogenerated from source/nptl_barrier.c.m4 */
/*
 * PM2: Parallel Multithreaded Machine
 * Copyright (C) 2001 "the PM2 team" (see AUTHORS file)
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or (at
 * your option) any later version.
 *
 * This program is distributed in the hope that it will be useful, but
 * WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * General Public License for more details.
 */
#include "marcel.h"

#include <errno.h>

#include "marcel_fastlock.h"

#ifdef MA__LIBPTHREAD
DEF_LIBPTHREAD(int, barrierattr_init,
	       (pthread_barrierattr_t * attr),
	       (attr))
DEF___LIBPTHREAD(int, barrierattr_init,
		 (pthread_barrierattr_t * attr),
		 (attr))
DEF_LIBPTHREAD(int, barrierattr_destroy,
	       (pthread_barrierattr_t * attr),
	       (attr))
DEF___LIBPTHREAD(int, barrierattr_destroy,
		 (pthread_barrierattr_t * attr),
		 (attr))
DEF_LIBPTHREAD(int, barrierattr_getpshared,
	       (pthread_barrierattr_t * __restrict attr, int *__restrict pshared),
	       (attr, pshared))
DEF_LIBPTHREAD(int, barrierattr_setpshared,
	       (pthread_barrierattr_t * attr, int pshared),
	       (attr, pshared))
versioned_symbol(libpthread, lpt_barrier_init, pthread_barrier_init, GLIBC_2_2);
versioned_symbol(libpthread, lpt_barrier_destroy, pthread_barrier_destroy, GLIBC_2_2);
versioned_symbol(libpthread, lpt_barrier_wait, pthread_barrier_wait, GLIBC_2_2);
#endif

#ifdef MA__IFACE_LPT
int lpt_barrierattr_init(lpt_barrierattr_t * _attr)
{
	struct lpt_barrierattr *const attr = (struct lpt_barrierattr *) _attr;
	MARCEL_LOG_IN();
	attr->pshared = LPT_PROCESS_PRIVATE;
	MARCEL_LOG_RETURN(0);
}

int lpt_barrierattr_destroy(lpt_barrierattr_t * attr TBX_UNUSED)
{
	MARCEL_LOG_IN();
	/* Nothing to do.  */
	MARCEL_LOG_RETURN(0);
}

int lpt_barrierattr_getpshared(__const lpt_barrierattr_t * _attr, int *pshared)
{
	struct lpt_barrierattr *const attr = (struct lpt_barrierattr *) _attr;
	MARCEL_LOG_IN();
	*pshared = attr->pshared;
	MARCEL_LOG_RETURN(0);
}

int lpt_barrierattr_setpshared(lpt_barrierattr_t * _attr, int pshared)
{
	struct lpt_barrierattr *const attr = (struct lpt_barrierattr *) _attr;
	MARCEL_LOG_IN();
	if (pshared != LPT_PROCESS_PRIVATE
	    && __builtin_expect(pshared != LPT_PROCESS_SHARED, 0)) {
		MARCEL_LOG_RETURN(EINVAL);
	}
	if (pshared == LPT_PROCESS_SHARED) {
		MARCEL_LOG_RETURN(ENOTSUP);
	}
	attr->pshared = pshared;
	MARCEL_LOG_RETURN(0);
}

int lpt_barrier_init(lpt_barrier_t * _b,
		     __const lpt_barrierattr_t * _attr, unsigned int count)
{
	struct lpt_barrier *const b = (struct lpt_barrier *) _b;
	struct lpt_barrierattr *const attr = (struct lpt_barrierattr *) _attr;
	MARCEL_LOG_IN();
	if (__builtin_expect(count == 0, 0)) {
		MARCEL_LOG_RETURN(EINVAL);
	}
	if (attr != NULL) {
		if (attr->pshared != LPT_PROCESS_PRIVATE
		    && __builtin_expect(attr->pshared != LPT_PROCESS_SHARED, 0)) {
			MARCEL_LOG_RETURN(EINVAL);
		}
		if (attr->pshared == LPT_PROCESS_SHARED) {
			MARCEL_LOG_RETURN(ENOTSUP);
		}
	}
	b->lock = (struct _lpt_fastlock) MA_LPT_FASTLOCK_UNLOCKED;
	b->init_count = count;
	ma_atomic_init(&b->leftB, count);
	ma_atomic_init(&b->leftE, 0);
	MARCEL_LOG_RETURN(0);
}

int lpt_barrier_destroy(lpt_barrier_t * _b)
{
	struct lpt_barrier *const b = (struct lpt_barrier *) _b;
	int ret = 0;
	MARCEL_LOG_IN();
	lpt_fastlock_acquire(&b->lock);
	while (ma_atomic_read(&b->leftE)) {
		lpt_blockcell_t c;
		__lpt_register_spinlocked(&b->lock, ma_self(), &c);
		INTERRUPTIBLE_SLEEP_ON_CONDITION_RELEASING(c.blocked,
							   lpt_fastlock_release(&b->lock),
							   lpt_fastlock_acquire
							   (&b->lock));
	}
	if (__builtin_expect(ma_atomic_read(&b->leftB) != (int) b->init_count, 0)) {
		ret = EBUSY;
	}
	lpt_fastlock_release(&b->lock);
	MARCEL_LOG_RETURN(ret);
}

int lpt_barrier_wait(lpt_barrier_t * b)
{
	int ret = 0;
	MARCEL_LOG_IN();
	lpt_barrier_wait_begin(b);
	if (!lpt_barrier_wait_end(b))
		ret = LPT_BARRIER_SERIAL_THREAD;
	MARCEL_LOG_RETURN(ret);
}

int lpt_barrier_wait_begin(lpt_barrier_t * _b)
{
	struct lpt_barrier *const b = (struct lpt_barrier *) _b;
	MARCEL_LOG_IN();
	lpt_fastlock_acquire(&b->lock);
	while (ma_atomic_read(&b->leftE)) {
		lpt_blockcell_t c;
		__lpt_register_spinlocked(&b->lock, ma_self(), &c);
		INTERRUPTIBLE_SLEEP_ON_CONDITION_RELEASING(c.blocked,
							   lpt_fastlock_release(&b->lock),
							   lpt_fastlock_acquire
							   (&b->lock));
	}
	int ret = ma_atomic_dec_return(&b->leftB);
	if (!ret) {
		while (__lpt_unlock_spinlocked(&b->lock));
		ma_atomic_set(&b->leftB, b->init_count);
		ma_atomic_set(&b->leftE, b->init_count);
	}
	lpt_fastlock_release(&b->lock);
	MARCEL_LOG_RETURN(ret);
}

int lpt_barrier_wait_end(lpt_barrier_t * _b)
{
	struct lpt_barrier *const b = (struct lpt_barrier *) _b;
	MARCEL_LOG_IN();
	lpt_fastlock_acquire(&b->lock);
	while (!ma_atomic_read(&b->leftE)) {
		lpt_blockcell_t c;
		__lpt_register_spinlocked(&b->lock, ma_self(), &c);
		INTERRUPTIBLE_SLEEP_ON_CONDITION_RELEASING(c.blocked,
							   lpt_fastlock_release(&b->lock),
							   lpt_fastlock_acquire
							   (&b->lock));
	}
	int ret = ma_atomic_dec_return(&b->leftE);
	if (!ret)
		while (__lpt_unlock_spinlocked(&b->lock));
	lpt_fastlock_release(&b->lock);
	MARCEL_LOG_RETURN(ret);
}
#endif
