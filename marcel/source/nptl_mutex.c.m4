dnl -*- linux-c -*-
include(scripts/marcel.m4)
dnl /***************************
dnl  * This is the original file
dnl  * =========================
dnl  ***************************/
/* This file has been autogenerated from __file__ */
/*
 * PM2: Parallel Multithreaded Machine
 * Copyright (C) 2001 "the PM2 team" (see AUTHORS file)
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or (at
 * your option) any later version.
 *
 * This program is distributed in the hope that it will be useful, but
 * WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * General Public License for more details.
 */
#include "marcel.h"

#include <errno.h>

#include "marcel_fastlock.h"

/****************************************************************
 * MUTEX
 */

     /**************/
     /* mutex_init */
     /**************/
PRINT_PTHREAD([[dnl
DEF_LIBPTHREAD(int, mutex_init,
	  (pthread_mutex_t * mutex, const pthread_mutexattr_t * mutex_attr),
	  (mutex, mutex_attr))
DEF___LIBPTHREAD(int, mutex_init,
	  (pthread_mutex_t * mutex, const pthread_mutexattr_t * mutex_attr),
	  (mutex, mutex_attr))
]])

REPLICATE_CODE([[dnl
int prefix_mutex_init (prefix_mutex_t *mutex, 
		       const prefix_mutexattr_t * mutexattr)
{
        LOG_IN();
        mdebug("initializing mutex %p by %p\n", mutex, marcel_self());
	__marcel_init_lock(&mutex->__data.__lock);
        LOG_RETURN(0);
}
]], [[MARCEL]])

REPLICATE_CODE([[dnl
static const struct prefix_mutexattr prefix_default_attr =
{
	/* Default is a normal mutex, not shared between processes.  */
	.mutexkind = PREFIX_MUTEX_NORMAL
};

int prefix_mutex_init (prefix_mutex_t *mutex, 
		       const prefix_mutexattr_t * mutexattr)
{
        LOG_IN();
	const struct prefix_mutexattr *imutexattr;
        mdebug("initializing mutex %p by %p\n", mutex, marcel_self());

#if MA__MODE == MA__MODE_LPT
	MA_BUG_ON (sizeof (lpt_mutex_t) > __SIZEOF_LPT_MUTEX_T);
#endif

	imutexattr = (const struct prefix_mutexattr *) mutexattr 
		?: &prefix_default_attr;

	/* Clear the whole variable.  */
	memset (mutex, '\0', sizeof(prefix_mutex_t));

	/* Copy the values from the attribute.  */
	mutex->__data.__kind = imutexattr->mutexkind & ~0x80000000;
	/* Default values: mutex not used yet.  */
	// mutex->__count = 0;        already done by memset
	// mutex->__owner = 0;        already done by memset
	// mutex->__nusers = 0;       already done by memset
	// mutex->__spins = 0;        already done by memset
	
        __prefix_init_lock(&mutex->__data.__lock);
        
        LOG_RETURN(0);
}
]], [[PMARCEL LPT]])

     /*****************/
     /* mutex_destroy */
     /*****************/
PRINT_PTHREAD([[dnl
DEF_LIBPTHREAD(int, mutex_destroy, (pthread_mutex_t * mutex), (mutex))
DEF___LIBPTHREAD(int, mutex_destroy, (pthread_mutex_t * mutex), (mutex))
]])

REPLICATE_CODE([[dnl
int prefix_mutex_destroy(prefix_mutex_t * mutex)
{
        LOG_IN();
        /* #if MA__MODE == MA__MODE_LPT || MA__MODE == MA__MODE_PMARCEL */
        /*    if (mutex->__data.__nusers != 0) */
        /*       return EBUSY; */
        /* #endif */
        LOG_RETURN(0);
}
]],[[MARCEL PMARCEL LPT]])


     /**************/
     /* mutex_lock */
     /**************/
PRINT_PTHREAD([[dnl
DEF___LIBPTHREAD(int, mutex_lock, (pthread_mutex_t * mutex), (mutex))
]])

REPLICATE_CODE([[dnl
int prefix_mutex_lock(prefix_mutex_t * mutex)
{
        LOG_IN();
   struct marcel_task *id = MARCEL_SELF;
   __marcel_lock(&mutex->__data.__lock, id);
        LOG_RETURN(0);
}
]], [[MARCEL]])

REPLICATE_CODE([[dnl
int prefix_mutex_lock(prefix_mutex_t * mutex)
{
        LOG_IN();
	struct marcel_task *id = MARCEL_SELF;

#if MA__MODE == MA__MODE_LPT
	MA_BUG_ON (sizeof (mutex->__size) < sizeof (mutex->__data));
#endif
        switch (__builtin_expect (mutex->__data.__kind, PREFIX_MUTEX_TIMED_NP)) {
		/* Recursive mutex.  */
	case PREFIX_MUTEX_RECURSIVE_NP:
		/* Check whether we already hold the mutex.  */
                        if (mutex->__data.__owner == id) {
			/* Just bump the counter.  */
			if (__builtin_expect (mutex->__data.__count + 1 == 0, 0))
				/* Overflow of the counter.  */
                                        LOG_RETURN(EAGAIN);
			++mutex->__data.__count;
                                LOG_RETURN(0);
		}
		
		/* We have to get the mutex.  */
		__prefix_lock(&mutex->__data.__lock, id);
		
		mutex->__data.__count = 1;
		break;
		
		/* Error checking mutex.  */
	case PREFIX_MUTEX_ERRORCHECK_NP:
		/* Check whether we already hold the mutex.  */
		if (mutex->__data.__owner == id)
                                LOG_RETURN(EDEADLK);

                default:
		
	case PREFIX_MUTEX_TIMED_NP:
	case PREFIX_MUTEX_ADAPTIVE_NP:
		/* Normal mutex.  */
		__prefix_lock(&mutex->__data.__lock, id);
                break;		      
	}
	
	/* Record the ownership.  */
	MA_BUG_ON (mutex->__data.__owner != 0);
	mutex->__data.__owner = id;
	++mutex->__data.__nusers;
	
                LOG_RETURN(0);
}
]], [[PMARCEL LPT]])

#ifdef MA__LIBPTHREAD
versioned_symbol(libpthread, lpt_mutex_lock,
		pthread_mutex_lock, GLIBC_2_0);
#endif

     /*****************/
     /* mutex_trylock */
     /*****************/
PRINT_PTHREAD([[dnl
DEF_LIBPTHREAD(int, mutex_trylock, (pthread_mutex_t * mutex), (mutex))
DEF___LIBPTHREAD(int, mutex_trylock, (pthread_mutex_t * mutex), (mutex))
]])

REPLICATE_CODE([[dnl
int prefix_mutex_trylock(prefix_mutex_t * mutex)
{
        LOG_IN();
        LOG_RETURN(__marcel_trylock(&mutex->__data.__lock));
}
]], [[MARCEL]])

REPLICATE_CODE([[dnl
int prefix_mutex_trylock(prefix_mutex_t * mutex)
{
        LOG_IN();
	struct marcel_task *id;

        switch (__builtin_expect (mutex->__data.__kind, PREFIX_MUTEX_TIMED_NP)) {
		/* Recursive mutex.  */
	case PREFIX_MUTEX_RECURSIVE_NP:
		id = MARCEL_SELF;
		/* Check whether we already hold the mutex.  */
                        if (mutex->__data.__owner == id) {
			/* Just bump the counter.  */
			if (tbx_unlikely (mutex->__data.__count + 1 == 0))
				/* Overflow of the counter.  */
                                        LOG_RETURN(EAGAIN);
			++mutex->__data.__count;
                                LOG_RETURN(0);
		}
		
                        if (__prefix_trylock(&mutex->__data.__lock) != 0) {
			/* Record the ownership.  */
			mutex->__data.__owner = id;
			mutex->__data.__count = 1;
			++mutex->__data.__nusers;
			return 0;
		}
		break;
		
	case PREFIX_MUTEX_ERRORCHECK_NP:
		/* Error checking mutex.  We do not check for deadlocks.  */
	default:
		/* Correct code cannot set any other type.  */
	case PREFIX_MUTEX_TIMED_NP:
	case PREFIX_MUTEX_ADAPTIVE_NP:
		/* Normal mutex.  */
                        if (__prefix_trylock(&mutex->__data.__lock) != 0) {
			/* Record the ownership.  */
			mutex->__data.__owner = MARCEL_SELF;
                                ++mutex->__data.__nusers;	
                                LOG_RETURN(0);
		}
	}
	
        LOG_RETURN(EBUSY);
}
]], [[PMARCEL LPT]])


     /*******************/
     /* mutex_timedlock */
     /*******************/
REPLICATE_CODE([[dnl
static int prefix_mutex_blockcell(prefix_mutex_t * mutex,const struct timespec *abstime)
{
        struct timeval now, tv;
        unsigned long int timeout;

        /* il faut arrondir au supérieur */
        tv.tv_sec = abstime->tv_sec;
        tv.tv_usec =(abstime->tv_nsec + 999) / 1000;
	
        gettimeofday(&now, NULL);
	
        if(timercmp(&tv, &now, <=)) {
                mdebug("prefix_mutex_blockcell : valeur temporelle invalide\n");
                LOG_RETURN(ETIMEDOUT);
        }
	
        timeout = (((tv.tv_sec*1e6 + tv.tv_usec) -
        		  (now.tv_sec*1e6 + now.tv_usec)) + marcel_gettimeslice()-1)/marcel_gettimeslice();

        prefix_lock_acquire(&mutex->__data.__lock.__spinlock); 

        {
                blockcell c;

                __prefix_register_spinlocked(&mutex->__data.__lock,
        		          marcel_self(), &c);

                //tant que c'est bloqué et qu'il y a du temps...
                while(c.blocked && timeout) {
                        ma_set_current_state(MA_TASK_INTERRUPTIBLE);
                        prefix_lock_release(&mutex->__data.__lock.__spinlock);
                        timeout = ma_schedule_timeout(timeout+1);
                        prefix_lock_acquire(&mutex->__data.__lock.__spinlock);
                }
                // si c'est encore bloqué (cad le temps est écoulé)
                if (c.blocked) {
                        if (__prefix_unregister_spinlocked(&mutex->__data.__lock, &c)) {
                                pm2debug("Strange, we should be in the queue !!! (%s:%d)\n", __FILE__, __LINE__);
                        }
                        //on sort	
                        prefix_lock_release(&mutex->__data.__lock.__spinlock);
                        LOG_RETURN(ETIMEDOUT);
                }
                prefix_lock_release(&mutex->__data.__lock.__spinlock);
        }
        LOG_RETURN(0);
}
]], [[PMARCEL LPT]])

REPLICATE_CODE([[dnl
int prefix_mutex_timedlock(prefix_mutex_t * mutex,const struct timespec *abstime)
{
        LOG_IN();

        marcel_t cthread = marcel_self();
        int ret;

  if (__builtin_expect (abstime->tv_nsec, 0) < 0
		  || __builtin_expect (abstime->tv_nsec, 0) >= 1000000000) {
                mdebug("prefix_mutex_timedlock : valeur temporelle invalide\n");       
                LOG_RETURN(EINVAL);
        }

        switch(mutex->__data.__kind) {
  
                case PREFIX_MUTEX_RECURSIVE_NP:
                        cthread = cthread;
                        if (mutex->__data.__owner == cthread) {
                                mutex->__data.__count++;
                                LOG_RETURN(0);
    }
                        if (mutex->__data.__nusers == 0)
                                mutex->__data.__count = 1;
                        else {
                                ret = prefix_mutex_blockcell(mutex,abstime);
                                if (ret)
                                        LOG_RETURN(ETIMEDOUT);
                                else
                                        mutex->__data.__count = 1;
      }
                break;

                case PREFIX_MUTEX_ERRORCHECK_NP:
                        cthread = cthread;
                        if (mutex->__data.__owner == cthread) 
                                LOG_RETURN(EDEADLK);
                        if (mutex->__data.__nusers != 0) {
                                ret = prefix_mutex_blockcell(mutex,abstime);
                                if (ret)
                                        LOG_RETURN(ETIMEDOUT);
                        }
                break;

                case PREFIX_MUTEX_ADAPTIVE_NP:
                case PREFIX_MUTEX_TIMED_NP:
                        if (mutex->__data.__nusers != 0) {
                                ret = prefix_mutex_blockcell(mutex,abstime);
                                if (ret)
                                        LOG_RETURN(ETIMEDOUT);
                        }
                break;
  
  default:
                        LOG_RETURN(EINVAL);
  }
    
        mutex->__data.__nusers ++;
        mutex->__data.__owner = cthread;
        __prefix_lock(&mutex->__data.__lock, NULL);
        LOG_RETURN(0);
}
]], [[PMARCEL LPT]])

PRINT_PTHREAD([[dnl
versioned_symbol(libpthread, lpt_mutex_timedlock,
	              pthread_mutex_timedlock, GLIBC_2_2);
]])

     /****************/
     /* mutex_unlock */
     /****************/
PRINT_PTHREAD([[dnl
DEF___LIBPTHREAD(int, mutex_unlock, (pthread_mutex_t * mutex), (mutex))
]])

REPLICATE_CODE([[dnl
int prefix_mutex_unlock(prefix_mutex_t * mutex)
{
        return __marcel_unlock(&mutex->__data.__lock);
}
]], [[MARCEL]])

REPLICATE_CODE([[dnl
int prefix_mutex_unlock_usercnt(prefix_mutex_t * mutex, int decr)
{
        LOG_IN();

        switch (__builtin_expect (mutex->__data.__kind, PREFIX_MUTEX_TIMED_NP)) {
	case PREFIX_MUTEX_RECURSIVE_NP:
		/* Recursive mutex.  */
		if (mutex->__data.__owner != MARCEL_SELF)
                                LOG_RETURN(EPERM);
		
		if (--mutex->__data.__count != 0)
			/* We still hold the mutex.  */
                                LOG_RETURN(0);
		break;
		
	case PREFIX_MUTEX_ERRORCHECK_NP:
		/* Error checking mutex.  */
		if (mutex->__data.__owner != MARCEL_SELF
		    //|| ! lll_mutex_islocked (mutex->__data.__lock)
			)
                        LOG_RETURN(EPERM);
		break;
		
	default:
		/* Correct code cannot set any other type.  */
	case PREFIX_MUTEX_TIMED_NP:
	case PREFIX_MUTEX_ADAPTIVE_NP:
		/* Normal mutex.  Nothing special to do.  */
		break;
	}
	
	/* Always reset the owner field.  */
	mutex->__data.__owner = 0;
	if (decr)
		/* One less user.  */
		--mutex->__data.__nusers;
	
	/* Unlock.  */
	__prefix_unlock(&mutex->__data.__lock);
	
        LOG_RETURN(0);
}
 
int prefix_mutex_unlock(prefix_mutex_t * mutex)
{
        LOG_IN();
        LOG_RETURN(prefix_mutex_unlock_usercnt (mutex, 1));
}
]], [[PMARCEL LPT]])

#ifdef MA__LIBPTHREAD
versioned_symbol(libpthread, lpt_mutex_unlock,
		pthread_mutex_unlock, GLIBC_2_0);
#endif

     /******************/
     /* mutexattr_init */
     /******************/
PRINT_PTHREAD([[dnl
DEF_LIBPTHREAD(int, mutexattr_init, (pthread_mutexattr_t *attr), (attr))
DEF___LIBPTHREAD(int, mutexattr_init, (pthread_mutexattr_t *attr), (attr))
]])

REPLICATE_CODE([[dnl
int prefix_mutexattr_init(prefix_mutexattr_t * attr)
{
        LOG_IN();
        LOG_RETURN(0);
}
]], [[MARCEL]])

REPLICATE_CODE([[dnl
int prefix_mutexattr_init(prefix_mutexattr_t * attr)
{
        LOG_IN();
#if MA__MODE == MA__MODE_LPT
	if (sizeof (struct prefix_mutexattr) != sizeof (prefix_mutexattr_t))
		memset (attr, '\0', sizeof (*attr));
#endif

	/* We use bit 31 to signal whether the mutex is going to be
	   process-shared or not.  By default it is zero, i.e., the
	   mutex is not process-shared.  */
	((struct prefix_mutexattr *) attr)->mutexkind = PREFIX_MUTEX_NORMAL;
	
        LOG_RETURN(0);
}
]], [[PMARCEL LPT]])

     /*********************/
     /* mutexattr_destroy */
     /*********************/
PRINT_PTHREAD([[dnl
DEF_LIBPTHREAD(int, mutexattr_destroy, (pthread_mutexattr_t *attr), (attr))
DEF___LIBPTHREAD(int, mutexattr_destroy, (pthread_mutexattr_t *attr), (attr))
]])

REPLICATE_CODE([[dnl
int prefix_mutexattr_destroy(prefix_mutexattr_t * attr)
{
        LOG_IN();
        LOG_RETURN(0);
}
]],[[MARCEL PMARCEL LPT]])


     /****************************/
     /* mutex_attrsettype/setkind_np */
     /****************************/
PRINT_PTHREAD([[dnl
weak_alias (lpt_mutexattr_settype, pthread_mutexattr_setkind_np)
DEF_LIBPTHREAD(int, mutexattr_settype, (pthread_mutexattr_t *attr, int kind), (attr, kind))
DEF___LIBPTHREAD(int, mutexattr_settype, (pthread_mutexattr_t *attr, int kind), (attr, kind))
]])

REPLICATE_CODE([[dnl
int prefix_mutexattr_settype(prefix_mutexattr_t * attr, int kind)
{
        LOG_IN();
	struct prefix_mutexattr *iattr;

        if (kind < PREFIX_MUTEX_NORMAL || kind > PREFIX_MUTEX_ADAPTIVE_NP) {
                mdebug("prefix_mutexattr_settype : valeur kind(%d) invalide\n",kind);
                LOG_RETURN(EINVAL);
	}
	iattr = (struct prefix_mutexattr *) attr;

	/* We use bit 31 to signal whether the mutex is going to be
	   process-shared or not.  */
	iattr->mutexkind = (iattr->mutexkind & 0x80000000) | kind;
        LOG_RETURN(0);
}
]], [[PMARCEL LPT]])


     /****************************/
     /* mutex_attrgettype/getkind_np */
     /****************************/
PRINT_PTHREAD([[dnl
weak_alias (lpt_mutexattr_gettype, pthread_mutexattr_getkind_np)
DEF_LIBPTHREAD(int, mutexattr_gettype, (pthread_mutexattr_t *attr, int kind), (attr, kind))
DEF___LIBPTHREAD(int, mutexattr_gettype, (pthread_mutexattr_t *attr, int kind), (attr, kind))
]])

REPLICATE_CODE([[dnl
int prefix_mutexattr_gettype(const prefix_mutexattr_t * __restrict attr,
	int * __restrict kind)
{
        LOG_IN();
	const struct prefix_mutexattr *iattr;
	iattr = (const struct prefix_mutexattr *) attr;

	/* We use bit 31 to signal whether the mutex is going to be
	   process-shared or not.  */
	*kind = iattr->mutexkind & ~0x80000000;

        LOG_RETURN(0);
}
]], [[PMARCEL LPT]])


     /********************/
     /* mutex_attrsetpshared */
     /********************/
PRINT_PTHREAD([[dnl
DEF_LIBPTHREAD(int, mutexattr_setpshared, (pthread_mutexattr_t *attr,
	int pshared), (attr, pshared))
]])

REPLICATE_CODE([[dnl
int prefix_mutexattr_setpshared(prefix_mutexattr_t * attr, int pshared)
{
        LOG_IN();
	struct prefix_mutexattr *iattr;

	if (pshared != PREFIX_PROCESS_PRIVATE
        	     && __builtin_expect (pshared != PREFIX_PROCESS_SHARED, 0)) {
                mdebug("prefix_mutexattr_setpshared : valeur pshared(%d)  invalide\n",pshared);
                LOG_RETURN(EINVAL);
   }
	/* For now it is not possible to share a mutex variable.  */
	if (pshared != MARCEL_PROCESS_PRIVATE) {
                fprintf(stderr,"prefix_mutexattr_setpshared : shared mutex requested!\n");
                LOG_RETURN(ENOTSUP);
	}

	iattr = (struct prefix_mutexattr *) attr;

	/* We use bit 31 to signal whether the mutex is going to be
	   process-shared or not.  */
	if (pshared == PREFIX_PROCESS_PRIVATE)
		iattr->mutexkind &= ~0x80000000;
	else
		iattr->mutexkind |= 0x80000000;

        LOG_RETURN(0);
}
]], [[PMARCEL LPT]])

     /********************/
     /* mutex_attrgetpshared */
     /********************/
PRINT_PTHREAD([[dnl
DEF_LIBPTHREAD(int, mutexattr_getpshared, (pthread_mutexattr_t * __restrict attr,
		int * __restrict pshared), (attr, pshared))
]])

REPLICATE_CODE([[dnl
int prefix_mutexattr_getpshared(const prefix_mutexattr_t * __restrict attr,
	int * __restrict pshared)
{
        LOG_IN();
	const struct prefix_mutexattr *iattr;
	
	iattr = (const struct prefix_mutexattr *) attr;

	/* We use bit 31 to signal whether the mutex is going to be
	   process-shared or not.  */
	*pshared = ((iattr->mutexkind & 0x80000000) != 0
		    ? PREFIX_PROCESS_SHARED : PREFIX_PROCESS_PRIVATE);
	
        LOG_RETURN(0);
}
]], [[PMARCEL LPT]])


     /****************************************************************
      * ONCE-ONLY EXECUTION
      */
#include <limits.h>
#ifdef MARCEL_ONCE_ENABLED

// XXX Vince, à corriger. On n'a pas lpt_mutex sur toutes les archis pour l'instant, donc j'ai mis un pmarcel_mutex pour que ça marchouille.
static marcel_mutex_t once_masterlock = MARCEL_MUTEX_INITIALIZER;
static marcel_cond_t once_finished = MARCEL_COND_INITIALIZER;
static int fork_generation = 0;	/* Child process increments this after fork. */

enum { NEVER = 0, IN_PROGRESS = 1, DONE = 2 };

/* If a thread is canceled while calling the init_routine out of
   marcel once, this handler will reset the once_control variable
   to the NEVER state. */

static void marcel_once_cancelhandler(void *arg)
{
	marcel_once_t *once_control = arg;

	marcel_mutex_lock(&once_masterlock);
	*once_control = NEVER;
	marcel_mutex_unlock(&once_masterlock);
	marcel_cond_broadcast(&once_finished);
}

REPLICATE_CODE([[dnl
int prefix_once(prefix_once_t * once_control, 
	void (*init_routine)(void))
{
        LOG_IN();
	/* flag for doing the condition broadcast outside of mutex */
	int state_changed;

	static int _inited = 0;
	if (!_inited) {
		marcel_init_section(MA_INIT_MAIN_LWP);
		_inited = 1;
	}

	/* Test without locking first for speed */
	if (*once_control == DONE) {
		READ_MEMORY_BARRIER();
                LOG_RETURN(0);
	}
	/* Lock and test again */
	
	state_changed = 0;
	
	marcel_mutex_lock(&once_masterlock);
	
	/* If this object was left in an IN_PROGRESS state in a parent
	   process (indicated by stale generation field), reset it to NEVER. */
	if ((*once_control & 3) == IN_PROGRESS && (*once_control & ~3) != fork_generation)
		*once_control = NEVER;
	
	/* If init_routine is being called from another routine, wait until
	   it completes. */
	while ((*once_control & 3) == IN_PROGRESS) {
		marcel_cond_wait(&once_finished, &once_masterlock);
	}
	/* Here *once_control is stable and either NEVER or DONE. */
	if (*once_control == NEVER) {
		*once_control = IN_PROGRESS | fork_generation;
		marcel_mutex_unlock(&once_masterlock);
		marcel_cleanup_push(marcel_once_cancelhandler, once_control);
		init_routine();
		marcel_cleanup_pop(0);
		marcel_mutex_lock(&once_masterlock);
		WRITE_MEMORY_BARRIER();
		*once_control = DONE;
		state_changed = 1;
	}
	marcel_mutex_unlock(&once_masterlock);
	
	if (state_changed)
		marcel_cond_broadcast(&once_finished);
	
        LOG_RETURN(0);
}
]],[[MARCEL PMARCEL LPT]])

PRINT_PTHREAD([[dnl
DEF_LIBPTHREAD(int, once, (pthread_once_t *once_control,
	                   void (*init_routine)(void)),
	       (once_control, init_routine))
DEF___LIBPTHREAD(int, once, (pthread_once_t *once_control,
	                   void (*init_routine)(void)),
	       (once_control, init_routine))
]])


/*
 * Handle the state of the marcel_once mechanism across forks.  The
 * once_masterlock is acquired in the parent process prior to a fork to ensure
 * that no thread is in the critical region protected by the lock.  After the
 * fork, the lock is released. In the child, the lock and the condition
 * variable are simply reset.  The child also increments its generation
 * counter which lets marcel_once calls detect stale IN_PROGRESS states
 * and reset them back to NEVER.
 */

REPLICATE_CODE([[dnl
void prefix_once_fork_prepare(void)
{
	marcel_mutex_lock(&once_masterlock);
}

void prefix_once_fork_parent(void)
{
	marcel_mutex_unlock(&once_masterlock);
}

void prefix_once_fork_child(void)
{
	marcel_mutex_init(&once_masterlock, NULL);
	marcel_cond_init(&once_finished, NULL);
	if (fork_generation <= INT_MAX - 4)
		fork_generation += 4;	/* leave least significant two bits zero */
	else
		fork_generation = 0;
}
]],[[LPT]])

PRINT_PTHREAD([[dnl
//__DEF___PTHREAD(void, once_fork_prepare, (void), ())
//__DEF___PTHREAD(void, once_fork_parent, (void), ())
//__DEF___PTHREAD(void, once_fork_child, (void), ())
DEF___LIBPTHREAD(void, once_fork_prepare, (void), ())
DEF___LIBPTHREAD(void, once_fork_parent, (void), ())
DEF___LIBPTHREAD(void, once_fork_child, (void), ())
]])
//#endif
#endif /* MARCEL_ONCE_ENABLED */
