
/* This file has been autogenerated from source/nptl_mutex.c.m4 */
/*
 * PM2: Parallel Multithreaded Machine
 * Copyright (C) 2001 "the PM2 team" (see AUTHORS file)
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or (at
 * your option) any later version.
 *
 * This program is distributed in the hope that it will be useful, but
 * WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * General Public License for more details.
 */


#include "marcel.h"
#include <errno.h>


#ifdef MA__IFACE_LPT

static const struct lpt_mutexattr lpt_default_attr = {
	/* Default is a normal mutex, not shared between processes.  */
	.mutexkind = LPT_MUTEX_NORMAL
};

int lpt_mutex_init(lpt_mutex_t * mutex, const lpt_mutexattr_t * mutexattr)
{
	const struct lpt_mutexattr *imutexattr;
	const struct _lpt_fastlock initlock = MA_LPT_FASTLOCK_UNLOCKED;

	MARCEL_LOG_IN();

	MARCEL_LOG("initializing mutex %p by %p\n", mutex, ma_self());
	MA_BUG_ON(sizeof(lpt_mutex_t) > __SIZEOF_LPT_MUTEX_T);

	imutexattr = (const struct lpt_mutexattr *) mutexattr ? : &lpt_default_attr;
	memset(mutex, '\0', sizeof(lpt_mutex_t));

	/* Copy the values from the attribute.  */
	mutex->__data.__kind = imutexattr->mutexkind & ~0x80000000;
	mutex->__data.__lock = initlock;

	MARCEL_LOG_RETURN(0);
}
DEF_LIBPTHREAD(int, mutex_init, (pthread_mutex_t * m, const pthread_mutexattr_t * a), (m, a))
DEF___LIBPTHREAD(int, mutex_init, (pthread_mutex_t * m, const pthread_mutexattr_t * a), (m, a))


int lpt_mutex_destroy(lpt_mutex_t * mutex)
{
	MARCEL_LOG_IN();
	__lpt_destroy_lock(&mutex->__data.__lock);
	MARCEL_LOG_RETURN(0);
}
DEF_LIBPTHREAD(int, mutex_destroy, (pthread_mutex_t * m), (m))
DEF___LIBPTHREAD(int, mutex_destroy, (pthread_mutex_t * m), (m))


int lpt_mutex_lock(lpt_mutex_t * mutex)
{
	MARCEL_LOG_IN();

	MA_BUG_ON(sizeof(mutex->__size) < sizeof(mutex->__data));
	switch (mutex->__data.__kind) {
	        case LPT_MUTEX_RECURSIVE_NP:
			/* Check whether we already hold the mutex.  */
			if (mutex->__data.__owner == ma_self()) {
				/* Just bump the counter.  */
				if (__builtin_expect(mutex->__data.__count + 1 == 0, 0))
					/* Overflow of the counter.  */
					MARCEL_LOG_RETURN(EAGAIN);
				++mutex->__data.__count;
				MARCEL_LOG_RETURN(0);
			}
			break;

	        case LPT_MUTEX_ERRORCHECK_NP:
			/* Check whether we already hold the mutex.  */
			if (mutex->__data.__owner == ma_self())
				MARCEL_LOG_RETURN(EDEADLK);
			break;
	}

	/* Get the mutex */
	__lpt_lock(&mutex->__data.__lock, ma_self());
	mutex->__data.__count = 1;

	/* Record the ownership.  */
	mutex->__data.__owner = ma_self();
	++mutex->__data.__nusers;

	MARCEL_LOG_RETURN(0);
}
versioned_symbol(libpthread, lpt_mutex_lock, pthread_mutex_lock, GLIBC_2_0);
DEF___LIBPTHREAD(int, mutex_lock, (pthread_mutex_t * m), (m))


int lpt_mutex_trylock(lpt_mutex_t * mutex)
{
	MARCEL_LOG_IN();

	if (mutex->__data.__kind == LPT_MUTEX_RECURSIVE_NP) {
		/* Check whether we already hold the mutex.  */
		if (mutex->__data.__owner == ma_self()) {
			/* Just bump the counter.  */
			if (tbx_unlikely(mutex->__data.__count + 1 == 0))
				/* Overflow of the counter.  */
				MARCEL_LOG_RETURN(EAGAIN);
			++mutex->__data.__count;
			MARCEL_LOG_RETURN(0);
		}
	}

	if (__lpt_trylock(&mutex->__data.__lock) != 0) {
		/* Record the ownership.  */
		mutex->__data.__owner = ma_self();
		mutex->__data.__count = 1;
		++mutex->__data.__nusers;
		MARCEL_LOG_RETURN(0);
	}

	MARCEL_LOG_RETURN(EBUSY);
}
DEF_LIBPTHREAD(int, mutex_trylock, (pthread_mutex_t * m), (m))
DEF___LIBPTHREAD(int, mutex_trylock, (pthread_mutex_t * m), (m))


static int __lpt_mutex_blockcell(lpt_mutex_t * mutex, const struct timespec *abstime)
{
	struct timeval now, tv;
	unsigned long int timeout;
	int ret;

	/* must round-up */
	tv.tv_sec = abstime->tv_sec;
	tv.tv_usec = (abstime->tv_nsec + 999) / 1000;
	gettimeofday(&now, NULL);
	if (timercmp(&tv, &now, <=)) {
		MARCEL_LOG("lpt_mutex_blockcell : valeur temporelle invalide\n");
		MARCEL_LOG_RETURN(ETIMEDOUT);
	}
	timeout = MA_TIMEVAL_TO_USEC(&tv) - MA_TIMEVAL_TO_USEC(&now);

	lpt_fastlock_acquire(&mutex->__data.__lock);
	ret = __lpt_lock_timed_wait(&mutex->__data.__lock, ma_self(), timeout, 0);
	lpt_fastlock_release(&mutex->__data.__lock);
	MARCEL_LOG_RETURN(ret);
}

int lpt_mutex_timedlock(lpt_mutex_t * mutex, const struct timespec *abstime)
{
	MARCEL_LOG_IN();

	if (__builtin_expect(abstime->tv_nsec, 0) < 0
	    || __builtin_expect(abstime->tv_nsec, 0) >= 1000000000) {
		MARCEL_LOG("lpt_mutex_timedlock : valeur temporelle invalide\n");
		MARCEL_LOG_RETURN(EINVAL);
	}

	switch (mutex->__data.__kind) {
	        case LPT_MUTEX_RECURSIVE_NP:
			if (mutex->__data.__owner == ma_self()) {
				mutex->__data.__count++;
				MARCEL_LOG_RETURN(0);
			}
			break;

	        case LPT_MUTEX_ERRORCHECK_NP:
			if (mutex->__data.__owner == ma_self())
				MARCEL_LOG_RETURN(EDEADLK);
			break;
	}

	if (mutex->__data.__nusers != 0 && tbx_unlikely(__lpt_mutex_blockcell(mutex, abstime)))
		MARCEL_LOG_RETURN(ETIMEDOUT);

	__lpt_lock(&mutex->__data.__lock, NULL);
	mutex->__data.__count = 1;
	mutex->__data.__nusers++;
	mutex->__data.__owner = ma_self();

	MARCEL_LOG_RETURN(0);
}
versioned_symbol(libpthread, lpt_mutex_timedlock, pthread_mutex_timedlock, GLIBC_2_2);


int lpt_mutex_unlock(lpt_mutex_t * mutex)
{
	MARCEL_LOG_IN();

	switch (mutex->__data.__kind) {
	        case LPT_MUTEX_RECURSIVE_NP:
			if (mutex->__data.__owner != MARCEL_SELF)
				MARCEL_LOG_RETURN(EPERM);

			if (--mutex->__data.__count != 0)
				/* We still hold the mutex.  */
				MARCEL_LOG_RETURN(0);
			break;

	        case LPT_MUTEX_ERRORCHECK_NP:
			if (mutex->__data.__owner != MARCEL_SELF)
				MARCEL_LOG_RETURN(EPERM);

	        default:
			mutex->__data.__count = 0;
			break;
	}

	/* Always reset the owner field.  */
	mutex->__data.__owner = 0;
	--mutex->__data.__nusers;

	/* Unlock.  */
	__lpt_unlock(&mutex->__data.__lock);

	MARCEL_LOG_RETURN(0);
}
versioned_symbol(libpthread, lpt_mutex_unlock, pthread_mutex_unlock, GLIBC_2_0);
DEF___LIBPTHREAD(int, mutex_unlock, (pthread_mutex_t * m), (m))


int lpt_mutexattr_init(lpt_mutexattr_t * attr)
{
	MARCEL_LOG_IN();
	if (sizeof(struct lpt_mutexattr) != sizeof(lpt_mutexattr_t))
		memset(attr, '\0', sizeof(*attr));

	/* We use bit 31 to signal whether the mutex is going to be
	   process-shared or not.  By default it is zero, i.e., the
	   mutex is not process-shared.  */
	((struct lpt_mutexattr *) attr)->mutexkind = LPT_MUTEX_NORMAL;

	MARCEL_LOG_RETURN(0);
}
DEF_LIBPTHREAD(int, mutexattr_init, (pthread_mutexattr_t * a), (a))
DEF___LIBPTHREAD(int, mutexattr_init, (pthread_mutexattr_t * a), (a))


int lpt_mutexattr_destroy(lpt_mutexattr_t * attr TBX_UNUSED)
{
	MARCEL_LOG_IN();
	MARCEL_LOG_RETURN(0);
}
DEF_LIBPTHREAD(int, mutexattr_destroy, (pthread_mutexattr_t * a), (a))
DEF___LIBPTHREAD(int, mutexattr_destroy, (pthread_mutexattr_t * a), (a))


int lpt_mutexattr_settype(lpt_mutexattr_t * attr, int kind)
{
	MARCEL_LOG_IN();
	struct lpt_mutexattr *iattr;

	if (kind < LPT_MUTEX_NORMAL || kind > LPT_MUTEX_ADAPTIVE_NP) {
		MARCEL_LOG("lpt_mutexattr_settype : valeur kind(%d) invalide\n", kind);
		MARCEL_LOG_RETURN(EINVAL);
	}

	if (attr) {
		iattr = (struct lpt_mutexattr *) attr;

		/* We use bit 31 to signal whether the mutex is going to be
		   process-shared or not.  */
		iattr->mutexkind = (iattr->mutexkind & 0x80000000) | kind;
		MARCEL_LOG_RETURN(0);
	}

	MARCEL_LOG_RETURN(EINVAL);
}
DEF_LIBPTHREAD(int, mutexattr_settype, (pthread_mutexattr_t * a, int v), (a, v))
DEF___LIBPTHREAD(int, mutexattr_settype, (pthread_mutexattr_t * a, int v), (a, v))
DEF_WEAK_ALIAS(lpt_mutexattr_settype, pthread_mutexattr_setkind_np)


int lpt_mutexattr_gettype(const lpt_mutexattr_t * __restrict attr, int *__restrict kind)
{
	const struct lpt_mutexattr *iattr;

	MARCEL_LOG_IN();

	if (! kind || ! attr)
		MARCEL_LOG_RETURN(EINVAL);

	/* We use bit 31 to signal whether the mutex is going to be
	   process-shared or not.  */
	iattr = (const struct lpt_mutexattr *) attr;
	*kind = iattr->mutexkind & ~0x80000000;
	MARCEL_LOG_RETURN(0);
}
DEF_LIBPTHREAD(int, mutexattr_gettype, (pthread_mutexattr_t * a, int *v), (a, v))
DEF___LIBPTHREAD(int, mutexattr_gettype, (pthread_mutexattr_t * a, int *v), (a, v))
DEF_WEAK_ALIAS(lpt_mutexattr_gettype, pthread_mutexattr_getkind_np)


int lpt_mutexattr_setpshared(lpt_mutexattr_t * attr, int pshared)
{
	MARCEL_LOG_IN();
	struct lpt_mutexattr *iattr;

	if (pshared != LPT_PROCESS_PRIVATE
	    && __builtin_expect(pshared != LPT_PROCESS_SHARED, 0)) {
		MARCEL_LOG("lpt_mutexattr_setpshared : valeur pshared(%d)  invalide\n",
			   pshared);
		MARCEL_LOG_RETURN(EINVAL);
	}
	/* For now it is not possible to share a mutex variable.  */
	if (pshared != MARCEL_PROCESS_PRIVATE) {
		MA_NOT_SUPPORTED("shared mutex");
		MARCEL_LOG_RETURN(ENOTSUP);
	}

	iattr = (struct lpt_mutexattr *) attr;

	/* We use bit 31 to signal whether the mutex is going to be
	   process-shared or not.  */
	if (pshared == LPT_PROCESS_PRIVATE)
		iattr->mutexkind &= ~0x80000000;
	else
		iattr->mutexkind |= 0x80000000;

	MARCEL_LOG_RETURN(0);
}
DEF_LIBPTHREAD(int, mutexattr_setpshared, (pthread_mutexattr_t * a, int v), (a, v))


int lpt_mutexattr_getpshared(const lpt_mutexattr_t * __restrict attr,
			     int *__restrict pshared)
{
	MARCEL_LOG_IN();
	const struct lpt_mutexattr *iattr;

	iattr = (const struct lpt_mutexattr *) attr;

	/* We use bit 31 to signal whether the mutex is going to be
	   process-shared or not.  */
	*pshared = ((iattr->mutexkind & 0x80000000) != 0
		    ? LPT_PROCESS_SHARED : LPT_PROCESS_PRIVATE);

	MARCEL_LOG_RETURN(0);
}
DEF_LIBPTHREAD(int, mutexattr_getpshared, (pthread_mutexattr_t * __restrict a, int *__restrict v), (a, v))


#include <limits.h>
#  ifdef MARCEL_ONCE_ENABLED
static marcel_mutex_t once_masterlock = MARCEL_MUTEX_INITIALIZER;
static marcel_cond_t once_finished = MARCEL_COND_INITIALIZER;
static int fork_generation = 0;	/* Child process increments this after fork. */

enum { NEVER = 0, IN_PROGRESS = 1, DONE = 2 };

#    ifdef MARCEL_DEVIATION_ENABLED
static void marcel_once_cancelhandler(void *arg)
{
	marcel_once_t *once_control = arg;

	marcel_mutex_lock(&once_masterlock);
	*once_control = NEVER;
	marcel_mutex_unlock(&once_masterlock);
	marcel_cond_broadcast(&once_finished);
}
#    endif				/* MARCEL_DEVIATION_ENABLED */

int lpt_once(lpt_once_t * once_control, void (*init_routine) (void))
{

	MARCEL_LOG_IN();
	/* flag for doing the condition broadcast outside of mutex */
	int state_changed;

	if (!marcel_test_activity()) {
		/* We're in single-threaded mode, so we can safely call INIT_ROUTINE.  */
		init_routine();
		*once_control = DONE;
		return 0;
	}

	/* Test without locking first for speed */
	if (*once_control == DONE) {
		ma_smp_rmb();
		MARCEL_LOG_RETURN(0);
	}
	/* Lock and test again */

	state_changed = 0;

	marcel_mutex_lock(&once_masterlock);

	/* If this object was left in an IN_PROGRESS state in a parent
	   process (indicated by stale generation field), reset it to NEVER. */
	if ((*once_control & 3) == IN_PROGRESS && (*once_control & ~3) != fork_generation)
		*once_control = NEVER;

	/* If init_routine is being called from another routine, wait until
	   it completes. */
	while ((*once_control & 3) == IN_PROGRESS) {
		marcel_cond_wait(&once_finished, &once_masterlock);
	}
	/* Here *once_control is stable and either NEVER or DONE. */
	if (*once_control == NEVER) {
		*once_control = IN_PROGRESS | fork_generation;
		marcel_mutex_unlock(&once_masterlock);
#ifdef MARCEL_DEVIATION_ENABLED
		marcel_cleanup_push(marcel_once_cancelhandler, once_control);
#endif				/* MARCEL_DEVIATION_ENABLED */
		init_routine();
#ifdef MARCEL_DEVIATION_ENABLED
		marcel_cleanup_pop(tbx_false);
#endif				/* MARCEL_DEVIATION_ENABLED */
		marcel_mutex_lock(&once_masterlock);
		ma_smp_wmb();
		*once_control = DONE;
		state_changed = 1;
	}
	marcel_mutex_unlock(&once_masterlock);

	if (state_changed)
		marcel_cond_broadcast(&once_finished);

	MARCEL_LOG_RETURN(0);
}
DEF_LIBPTHREAD(int, once, (pthread_once_t * ctrl, void (*init) (void)), (ctrl, init))
DEF___LIBPTHREAD(int, once, (pthread_once_t * ctrl, void (*init) (void)), (ctrl, init))


/*
 * Handle the state of the marcel_once mechanism across forks.  The
 * once_masterlock is acquired in the parent process prior to a fork to ensure
 * that no thread is in the critical region protected by the lock.  After the
 * fork, the lock is released. In the child, the lock and the condition
 * variable are simply reset.  The child also increments its generation
 * counter which lets marcel_once calls detect stale IN_PROGRESS states
 * and reset them back to NEVER.
 */
void lpt_once_fork_prepare(void)
{
	marcel_mutex_lock(&once_masterlock);
}
DEF___LIBPTHREAD(void, once_fork_prepare, (void), ())


void lpt_once_fork_parent(void)
{
	marcel_mutex_unlock(&once_masterlock);
}
DEF___LIBPTHREAD(void, once_fork_parent, (void), ())


void lpt_once_fork_child(void)
{
	marcel_mutex_init(&once_masterlock, NULL);
	marcel_cond_init(&once_finished, NULL);
	if (fork_generation <= INT_MAX - 4)
		fork_generation += 4;	/* leave least significant two bits zero */
	else
		fork_generation = 0;
}
DEF___LIBPTHREAD(void, once_fork_child, (void), ())


#  endif			/* MARCEL_ONCE_ENABLED */


#endif /** MA__IFACE_LPT **/
